#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements. See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership. The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License. You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied. See the License for the
# specific language governing permissions and limitations
# under the License.
#init
#  - cmd: SET PATH=%CONDA_INSTALL_LOCN%;%CONDA_INSTALL_LOCN%\Scripts;%PATH% 

#        conda install -y --quiet r-base r-evaluate r-base64enc r-knitr r-ggplot2 r-irkernel r-shiny r-googlevis
#        cmd /c 'R.exe -e "IRkernel::installspec()" 2>&1 '


version: '1.0.0-dev.{build}'

shallow_clone: true

build: off

os:
  - Visual Studio 2015

environment:
  
  INTERPRETERS: '!beam,!hbase,!pig,!jdbc,!file,!flink,!ignite,!kylin,!lens,!cassandra,!elasticsearch,!bigquery,!alluxio,!scio,!livy,!groovy,!sap,!java,!geode,!neo4j,!hazelcastjet,!submarine,!sparql,!mongodb'
  matrix:
#    - BUILD_NAME: "Run e2e tests in zeppelin-web"
#      BUILD_FLAG: install -DskipTests -DskipRat -pl !beam,!hbase,!pig,!jdbc,!file,!flink,!ignite,!kylin,!lens,!cassandra,!elasticsearch,!bigquery,!alluxio,!scio,!livy,!groovy,!sap,!java,!geode,!neo4j,!hazelcastjet,!submarine,!sparql,!mongodb -Phadoop2 -Pscala-2.11
#      TEST_FLAG: verify -DskipRat -pl zeppelin-web -Phadoop2 -Pscala-2.11 -Pweb-e2e-win
#    - BUILD_NAME: "Run tests in zeppelin-web-angular"
#      BUILD_FLAG: clean -DskipTests -DskipRat -pl "!beam,!hbase,!pig,!jdbc,!file,!flink,!ignite,!kylin,!lens,!cassandra,!elasticsearch,!bigquery,!alluxio,!scio,!livy,!groovy,!sap,!java,!geode,!neo4j,!hazelcastjet,!submarine,!sparql,!mongodb" -Phadoop2 -Pscala-2.11
#      TEST_FLAG: package -DskipRat -pl zeppelin-web-angular -Pweb-angular -Phadoop2 -Pscala-2.11
    - BUILD_NAME: "Test core modules (zeppelin-interpreter,zeppelin-zengine,zeppelin-server) on hadoop2"
      BUILD_FLAG: install -e -Pbuild-distr -DskipRat -DskipTests -pl zeppelin-server,zeppelin-web,spark/spark-dependencies,markdown,angular,shell -am -Phelium-dev -Pexamples -Phadoop2 -B
      TEST_FLAG: verify -e -Pusing-packaged-distr -Pwinexcludes -DskipRat -pl zeppelin-server,zeppelin-web,spark/spark-dependencies,markdown,angular,shell -am -Phelium-dev -Pexamples -Phadoop2 -B -Dtests.to.exclude='**/org/apache/zeppelin/spark/*,**/org/apache/zeppelin/jupyter/IRKernelTest' -DfailIfNoTests=false
      SPARK_PRINT_LAUNCH_COMMAND: true
      SPARK_VER: 2.3.2
      HADOOP_VER: 2.7
      PYTHON_APPVEYOR: 1
      CONDA_INSTALL_LOCN: C:\Miniconda37-x64
    - BUILD_NAME: "Test core modules (zeppelin-interpreter,zeppelin-zengine,zeppelin-server) on hadoop2 python2"
      BUILD_FLAG: install -e -Pbuild-distr -DskipRat -DskipTests -pl zeppelin-server,zeppelin-web,spark/spark-dependencies,markdown,angular,shell -am -Phelium-dev -Pexamples -Phadoop2 -B
      TEST_FLAG: verify -e -Pusing-packaged-distr -Pwinexcludes -DskipRat -pl zeppelin-server,zeppelin-web,spark/spark-dependencies,markdown,angular,shell -am -Phelium-dev -Pexamples -Phadoop2 -B -Dtests.to.exclude='**/org/apache/zeppelin/spark/*,**/org/apache/zeppelin/jupyter/IRKernelTest' -DfailIfNoTests=false
      SPARK_PRINT_LAUNCH_COMMAND: true
      SPARK_VER: 2.3.2
      HADOOP_VER: 2.7
      PYTHON_APPVEYOR: 1
      CONDA_INSTALL_LOCN: C:\Miniconda-x64
    - BUILD_NAME: "Test core modules (zeppelin-interpreter,zeppelin-zengine,zeppelin-server) on hadoop2 python2 32-bit"
      BUILD_FLAG: install -e -Pbuild-distr -DskipRat -DskipTests -pl zeppelin-server,zeppelin-web,spark/spark-dependencies,markdown,angular,shell -am -Phelium-dev -Pexamples -Phadoop2 -B
      TEST_FLAG: verify -e -Pusing-packaged-distr -Pwinexcludes -DskipRat -pl zeppelin-server,zeppelin-web,spark/spark-dependencies,markdown,angular,shell -am -Phelium-dev -Pexamples -Phadoop2 -B -Dtests.to.exclude='**/org/apache/zeppelin/spark/*,**/org/apache/zeppelin/jupyter/IRKernelTest' -DfailIfNoTests=false
      SPARK_PRINT_LAUNCH_COMMAND: true
      SPARK_VER: 2.3.2
      HADOOP_VER: 2.7
      PYTHON_APPVEYOR: 1
      CONDA_INSTALL_LOCN: C:\Miniconda
    - BUILD_NAME: "Test core modules (zeppelin-interpreter,zeppelin-zengine,zeppelin-server) on hadoop2 python37 32-bit"
      BUILD_FLAG: install -e -Pbuild-distr -DskipRat -DskipTests -pl zeppelin-server,zeppelin-web,spark/spark-dependencies,markdown,angular,shell -am -Phelium-dev -Pexamples -Phadoop2 -B
      TEST_FLAG: verify -e -Pusing-packaged-distr -Pwinexcludes -DskipRat -pl zeppelin-server,zeppelin-web,spark/spark-dependencies,markdown,angular,shell -am -Phelium-dev -Pexamples -Phadoop2 -B -Dtests.to.exclude='**/org/apache/zeppelin/spark/*,**/org/apache/zeppelin/jupyter/IRKernelTest' -DfailIfNoTests=false
      SPARK_PRINT_LAUNCH_COMMAND: true
      SPARK_VER: 2.3.2
      HADOOP_VER: 2.7
      PYTHON_APPVEYOR: 1
      CONDA_INSTALL_LOCN: C:\Miniconda37
    - BUILD_NAME: "Test core modules (zeppelin-interpreter,zeppelin-zengine,zeppelin-server) on hadoop2 python38 32-bit"
      BUILD_FLAG: install -e -Pbuild-distr -DskipRat -DskipTests -pl zeppelin-server,zeppelin-web,spark/spark-dependencies,markdown,angular,shell -am -Phelium-dev -Pexamples -Phadoop2 -B
      TEST_FLAG: verify -e -Pusing-packaged-distr -Pwinexcludes -DskipRat -pl zeppelin-server,zeppelin-web,spark/spark-dependencies,markdown,angular,shell -am -Phelium-dev -Pexamples -Phadoop2 -B -Dtests.to.exclude='**/org/apache/zeppelin/spark/*,**/org/apache/zeppelin/jupyter/IRKernelTest' -DfailIfNoTests=false
      SPARK_PRINT_LAUNCH_COMMAND: true
      SPARK_VER: 2.3.2
      HADOOP_VER: 2.7
      PYTHON_APPVEYOR: 1
      CONDA_INSTALL_LOCN: C:\Miniconda38  
init:
  - git config --global core.autocrlf true
  - ps: iex ((new-object net.webclient).DownloadString('https://raw.githubusercontent.com/appveyor/ci/master/scripts/enable-rdp.ps1'))
  - cmd: call %CONDA_INSTALL_LOCN%\Scripts\activate.bat

cache:
  - C:\Users\appveyor\.m2\repository\org\apache
  - C:\Users\appveyor\.m2\repository\org\codehaus
  - C:\Users\appveyor\.m2\repository\com
  - zeppelin-common\target
  - zeppelin-distribution\target
  - zeppelin-interpreter\target
  - zeppelin-interpreter-shaded\target
  - zeppelin-interpreter-parent\target
  - zeppelin-interpreter-integration\target
  - zeppelin-jupyter\target
  - zeppelin-jupyter-interpreter\target
  - zeppelin-jupyter-interpreter-shaded\target
  - zeppelin-web\target
  - zeppelin-web-angular\target
  - zeppelin-web\node
  - zeppelin-web\node_modules

install:
  - echo "Install"
  - cmd: echo %M2_HOME%
  - echo "%~nx0"
  - echo %CD%
  - cmd: mvn --version
  - cmd: java -version
  - ps: |     
      if (Test-Path env:SPARK_VER) {
        $SPARK_VERSION = $env:SPARK_VER
        $SPARK_VERSION = "2.3.2"
        $HADOOP_VERSION = $env:HADOOP_VER
        $HADOOP_VERSION = "2.7"
        $SPARK_ARCHIVE = "spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION"
        $SPARK_DL_URL = $('http://archive.apache.org/dist/spark/spark-' + $SPARK_VERSION + '/' + $SPARK_ARCHIVE + '.tgz')
        mkdir C:\Users\appveyor\.cache\spark\
        $SPARK_ABSPATH1 = $("C:\Users\appveyor\.cache\spark\" + $SPARK_ARCHIVE + ".tgz")
        $SPARK_ABSPATH2 = $("C:\Users\appveyor\.cache\spark\" + $SPARK_ARCHIVE + ".tar")
        Write-Output "Spark archive absolute path 1 : $SPARK_ABSPATH1" 
        Write-Output "Spark archive absolute path 2 : $SPARK_ABSPATH2" 
        Write-Output "Spark download url : $SPARK_DL_URL" 
        (new-object System.Net.WebClient).DownloadFile(
          $SPARK_DL_URL,
          $SPARK_ABSPATH1
        )
        $cont=true
        7z x $($SPARK_ABSPATH1) -oC:\Users\appveyor\.cache\spark\
        7z x $($SPARK_ABSPATH2) -oC:\Users\appveyor\.cache\spark\
        $WINUTILS_DL_URL = "https://github.com/steveloughran/winutils/raw/master/hadoop-2.7.1/bin/winutils.exe"
        $WINUTILS_TARGET = $("C:\Users\appveyor\.cache\spark\" + $SPARK_ARCHIVE + "\bin\winutils.exe")
        (new-object System.Net.WebClient).DownloadFile(
          $WINUTILS_DL_URL,
          $WINUTILS_TARGET
        )
      }
      if (Test-Path env:PYTHON_APPVEYOR) {
        $PYTHONMAJOR = (python -c "import sys;print(sys.version_info[0])")
        if ($PYTHONMAJOR -eq "2")
        {
          python -W ignore::DeprecationWarning -m pip install --upgrade pip
          pip install --no-python-version-warning -q psutil        
          pip install --no-python-version-warning -q numpy==1.14.5 pandas==0.21.1 matplotlib==2.1.1 scipy==1.2.1 grpcio==1.19.0 bkzep==0.6.1 hvplot==0.5.2 protobuf==3.7.0 pandasql==0.7.3 ipython==5.8.0 ipykernel==4.10.0 bokeh==1.3.4 panel==0.6.0 holoviews==1.12.3
        }
        else
        {
          python -W ignore::DeprecationWarning -m pip install --upgrade pip
          pip install -q psutil        
          pip install -q pycodestyle==2.5.0
          pip install -q numpy==1.17.3 pandas==0.25.0 scipy==1.3.1 grpcio==1.19.0 bkzep==0.6.1 hvplot==0.5.2 protobuf==3.10.0 pandasql==0.7.3 ipython==7.8.0 matplotlib==3.0.3 ipykernel==5.1.2 jupyter_client==5.3.4 bokeh==1.3.4 panel==0.6.0 holoviews==1.12.3 pycodestyle==2.5.0
        }
      }
      
build_script:
  - echo "Build  mvn %BUILD_FLAG% %MODULES% %PROFILE% -B"
  - cmd: mvn %BUILD_FLAG% %MODULES% %PROFILE% -B
  - echo "script-build-finished MARK"
  - ps: echo "Size of caches (bytes):"
  - ps: Get-ChildItem -Recurse 'C:\Users\appveyor\.m2\repository\org\apache' | Measure-Object -Property Length -Sum
test_script:
  - echo "Test mvn %TEST_FLAG% %TEST_MODULES% %PROFILE% -B %TEST_PROJECTS%"
  - cmd: mvn %TEST_FLAG% %TEST_MODULES% %PROFILE% -B %TEST_PROJECTS%
on_failure:
  - ps: $blockRdp = $true; iex ((new-object net.webclient).DownloadString('https://raw.githubusercontent.com/appveyor/ci/master/scripts/enable-rdp.ps1'))
#on_finish:

